{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import LSTM, StackedRNNCells, Dense, Flatten, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_content(file_path: str = \"tinyshakespeare.txt\"):\n",
    "    content = ''\n",
    "    with open(file_path, 'r') as in_file:\n",
    "        lines = in_file.readlines()\n",
    "        for line in lines:\n",
    "            content += line\n",
    "    return content\n",
    "\n",
    "\n",
    "def index_vucabulary(content: str):\n",
    "    char_freq = Counter(content)\n",
    "    char_freq = char_freq.most_common(len(char_freq))\n",
    "    voc_index = [(i, char_freq[i][0]) for i in range(len(char_freq))]\n",
    "\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    for item in voc_index:\n",
    "        vocab[item[0]] = item[1]\n",
    "        reverse_vocab[item[1]] = item[0]\n",
    "\n",
    "    return vocab, reverse_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, reverse_vocab = index_vucabulary(read_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(\n",
    "        text: List[str], reverse_vocab: Dict[str, int],\n",
    "        sequence_length: int=50, batch_size: int=64) -> tf.data.Dataset:\n",
    "\n",
    "    text_indices = np.array(list(map(lambda x: reverse_vocab[x], text)))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tensors=(text_indices))\n",
    "    #dataset = dataset.map(lambda x: tf.one_hot(x, depth=len(reverse_vocab), dtype=tf.float32))\n",
    "\n",
    "    dataset = dataset.batch(sequence_length, drop_remainder=True)\n",
    "    dataset = dataset.map(lambda x: (x[:-1], tf.one_hot(x[1:], depth=len(reverse_vocab), dtype=tf.float32)))\n",
    "    dataset = dataset.shuffle(buffer_size=100)\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "(64, 49) (64, 49, 65)\n"
     ]
    }
   ],
   "source": [
    "dataset = generate_dataset(read_content(), reverse_vocab)\n",
    "batch = next(iter(dataset))\n",
    "print(batch[0].shape, batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_text(model, sample_len: int=200) -> str:\n",
    "    # TODO: fix this logic to sample properly\n",
    "    context = next(iter(dataset))[0][:1]\n",
    "    h1 = tf.zeros((1, 512), dtype=tf.float32)\n",
    "    h2 = tf.zeros((1, 512), dtype=tf.float32)\n",
    "    sampled_text = \"\"\n",
    "\n",
    "    for t in range(context.shape[1]):\n",
    "        char_id = int(tf.argmax(tf.squeeze(context[:, t])))\n",
    "        sampled_text += vocab[char_id]\n",
    "    sampled_text += \"|\"\n",
    "\n",
    "    for i in range(sample_len):\n",
    "        new_context, h1, h2 = model((context, h1, h2))\n",
    "        new_context = np.concatenate((context[:, :-1], new_context[:, -1:]))\n",
    "        char_id = int(tf.argmax(tf.squeeze(context[:, -1])))\n",
    "        sampled_text += vocab[char_id]\n",
    "\n",
    "    return sampled_text\n",
    "\n",
    "\n",
    "class TextSampleCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nsampled text:\\n{sample_text(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 512)           33280     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 49, 1024)         4198400   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 49, 1024)          0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 49, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,298,305\n",
      "Trainable params: 4,298,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "348/348 [==============================] - 13s 23ms/step - loss: 0.6357 - accuracy: 0.8426\n",
      "Epoch 2/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0504 - accuracy: 0.9860\n",
      "Epoch 3/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0464 - accuracy: 0.9866\n",
      "Epoch 4/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0440 - accuracy: 0.9873\n",
      "Epoch 5/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0420 - accuracy: 0.9877\n",
      "Epoch 6/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0400 - accuracy: 0.9882\n",
      "Epoch 7/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0379 - accuracy: 0.9887\n",
      "Epoch 8/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0355 - accuracy: 0.9894\n",
      "Epoch 9/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0328 - accuracy: 0.9901\n",
      "Epoch 10/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0295 - accuracy: 0.9910\n",
      "Epoch 11/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0255 - accuracy: 0.9923\n",
      "Epoch 12/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0212 - accuracy: 0.9937\n",
      "Epoch 13/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0169 - accuracy: 0.9950\n",
      "Epoch 14/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0133 - accuracy: 0.9962\n",
      "Epoch 15/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0103 - accuracy: 0.9972\n",
      "Epoch 16/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0080 - accuracy: 0.9979\n",
      "Epoch 17/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0066 - accuracy: 0.9984\n",
      "Epoch 18/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 19/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0049 - accuracy: 0.9988\n",
      "Epoch 20/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0043 - accuracy: 0.9989\n",
      "Epoch 21/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 22/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "Epoch 23/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 24/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "Epoch 25/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 26/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 27/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 28/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 29/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 30/30\n",
      "348/348 [==============================] - 6s 18ms/step - loss: 0.0030 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f47f1795f40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(vocab), 512, input_length=49),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True)),\n",
    "    Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(len(vocab), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(epochs=30, x=dataset) #, callbacks=[TextSampleCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
